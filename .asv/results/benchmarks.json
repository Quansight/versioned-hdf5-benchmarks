{
    "delete_versions.TimeDeleting.time_delete": {
        "code": "class TimeDeleting:\n    def time_delete(self, n):\n        tmp_name = tempfile.mktemp(\".h5\")\n        shutil.copy2(filename, tmp_name)\n        try:\n            # want to keep only every 10th version\n            versions_to_delete = []\n            with h5py.File(tmp_name, \"r\") as f:\n                vf = VersionedHDF5File(f)\n                versions = sorted(\n                    [(v, vf._versions[v].attrs[\"timestamp\"]) for v in vf._versions],\n                    key=lambda t: t[1],\n                )\n                for i, v in enumerate(versions):\n                    if i % 10 != 0:\n                        versions_to_delete.append(v[0])\n    \n            with h5py.File(tmp_name, \"r+\") as f:\n                delete_versions(f, versions_to_delete)\n        finally:\n            os.remove(tmp_name)\n\n    def setup(self, n):\n        if not os.path.exists(filename):\n            with h5py.File(filename, \"w\") as f:\n                vf = VersionedHDF5File(f)\n                with vf.stage_version(\"init\") as sv:\n                    sv.create_dataset(\n                        \"values\",\n                        shape=(0, 0),\n                        dtype=\"float\",\n                        fillvalue=numpy.nan,\n                        chunks=(22, 100),\n                        maxshape=(None, None),\n                        compression=\"lzf\",\n                    )\n    \n            # generate some test data with around 1000 versions\n            v = 1\n            with h5py.File(filename, \"r+\") as f:\n                vf = VersionedHDF5File(f)\n                for d in range(3):\n                    with vf.stage_version(str(v)) as sv:\n                        values_ds = sv[\"values\"]\n                        values_ds.resize(\n                            (values_ds.shape[0] + 1, values_ds.shape[1] + 5000)\n                        )\n                        values_ds[-1, -5000] = numpy.random.rand()\n                        v += 1\n                    for c in range(n):\n                        with vf.stage_version(str(v)) as sv:\n                            values_ds = sv[\"values\"]\n                            idxs = numpy.random.choice(\n                                values_ds.shape[1], 50, replace=False\n                            )\n                            values_ds[-1, idxs] = numpy.random.rand(50)\n                            v += 1",
        "min_run_count": 2,
        "name": "delete_versions.TimeDeleting.time_delete",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "10",
                "30",
                "50"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "9f1a6f47e8ea566b4a70b924e8abdcedca341a38bd99f3244813c71a86358b1f",
        "warmup_time": -1
    },
    "hdf5.TimePureHDF5.time_getattr": {
        "code": "class TimePureHDF5:\n    def time_getattr(self):\n        dataset = self.file[\"data\"]\n        dataset[:, 0, 0:6]\n\n    def setup(self):\n        self.file = h5py.File(\"bench.hdf5\", \"w\")\n        self.file.create_dataset(\n            \"data\",\n            data=np.arange(10000).reshape((100, 10, 10)),\n            chunks=(3, 3, 3),\n            maxshape=(None, None, None),\n        )",
        "min_run_count": 2,
        "name": "hdf5.TimePureHDF5.time_getattr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fe88234d74987a7e61f3ed36913cdd175da2228ff04dfecc1bbee075874ea563",
        "warmup_time": -1
    },
    "hdf5.TimePureHDF5.time_resize_bigger": {
        "code": "class TimePureHDF5:\n    def time_resize_bigger(self):\n        dataset = self.file[\"data\"]\n        dataset.resize((100, 100, 100))\n\n    def setup(self):\n        self.file = h5py.File(\"bench.hdf5\", \"w\")\n        self.file.create_dataset(\n            \"data\",\n            data=np.arange(10000).reshape((100, 10, 10)),\n            chunks=(3, 3, 3),\n            maxshape=(None, None, None),\n        )",
        "min_run_count": 2,
        "name": "hdf5.TimePureHDF5.time_resize_bigger",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6b57ad13746413b2c46d4235caa3f857e4ef7f006276811b4388ee9aadea3ea2",
        "warmup_time": -1
    },
    "hdf5.TimePureHDF5.time_resize_smaller": {
        "code": "class TimePureHDF5:\n    def time_resize_smaller(self):\n        dataset = self.file[\"data\"]\n        dataset.resize((10, 10, 10))\n\n    def setup(self):\n        self.file = h5py.File(\"bench.hdf5\", \"w\")\n        self.file.create_dataset(\n            \"data\",\n            data=np.arange(10000).reshape((100, 10, 10)),\n            chunks=(3, 3, 3),\n            maxshape=(None, None, None),\n        )",
        "min_run_count": 2,
        "name": "hdf5.TimePureHDF5.time_resize_smaller",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "81f7e5934692835a257e65539414748cc9318d560015d555854a75587ce3ed40",
        "warmup_time": -1
    },
    "hdf5.TimePureHDF5.time_setattr": {
        "code": "class TimePureHDF5:\n    def time_setattr(self):\n        dataset = self.file[\"data\"]\n        dataset[:, 0, 0:6] = -1\n\n    def setup(self):\n        self.file = h5py.File(\"bench.hdf5\", \"w\")\n        self.file.create_dataset(\n            \"data\",\n            data=np.arange(10000).reshape((100, 10, 10)),\n            chunks=(3, 3, 3),\n            maxshape=(None, None, None),\n        )",
        "min_run_count": 2,
        "name": "hdf5.TimePureHDF5.time_setattr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "4f01648fd857ea11bb8d07dce44dca071e6265a0f09bd9278ac2695d7af9c4df",
        "warmup_time": -1
    },
    "inmemoryarraydataset.TimeInMemoryArrayDataset.time_getattr": {
        "code": "class TimeInMemoryArrayDataset:\n    def time_getattr(self):\n        with h5py.File(\"bench.hdf5\", \"w\") as f:\n            versioned_file = VersionedHDF5File(f)\n            with versioned_file.stage_version(\"version1\") as g:\n                dataset = g.create_dataset(\n                    \"data\",\n                    data=np.arange(10000).reshape((100, 10, 10)),\n                    chunks=(3, 3, 3),\n                )\n                assert isinstance(dataset.dataset, InMemoryArrayDataset)\n                dataset[:, 0, 0:6]",
        "min_run_count": 2,
        "name": "inmemoryarraydataset.TimeInMemoryArrayDataset.time_getattr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "1bee567df48d00e0a90bec3be5ad603439b5d1d5adb3b697a4f31d062a0f18aa",
        "warmup_time": -1
    },
    "inmemoryarraydataset.TimeInMemoryArrayDataset.time_resize_bigger": {
        "code": "class TimeInMemoryArrayDataset:\n    def time_resize_bigger(self):\n        with h5py.File(\"bench.hdf5\", \"w\") as f:\n            versioned_file = VersionedHDF5File(f)\n            with versioned_file.stage_version(\"version1\") as g:\n                dataset = g.create_dataset(\n                    \"data\",\n                    data=np.arange(10000).reshape((100, 10, 10)),\n                    chunks=(3, 3, 3),\n                )\n                assert isinstance(dataset.dataset, InMemoryArrayDataset)\n                dataset.resize((100, 100, 100))",
        "min_run_count": 2,
        "name": "inmemoryarraydataset.TimeInMemoryArrayDataset.time_resize_bigger",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "0da5c8ede9ed1afa48e54fa6671ce6f5ca2d6f676bc149aa33a219b0da3bbe8b",
        "warmup_time": -1
    },
    "inmemoryarraydataset.TimeInMemoryArrayDataset.time_resize_smaller": {
        "code": "class TimeInMemoryArrayDataset:\n    def time_resize_smaller(self):\n        with h5py.File(\"bench.hdf5\", \"w\") as f:\n            versioned_file = VersionedHDF5File(f)\n            with versioned_file.stage_version(\"version1\") as g:\n                dataset = g.create_dataset(\n                    \"data\",\n                    data=np.arange(10000).reshape((100, 10, 10)),\n                    chunks=(3, 3, 3),\n                )\n                assert isinstance(dataset.dataset, InMemoryArrayDataset)\n                dataset.resize((10, 10, 10))",
        "min_run_count": 2,
        "name": "inmemoryarraydataset.TimeInMemoryArrayDataset.time_resize_smaller",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "c71d1459ebaa06a38374593d3ece4f84bcc17afe534635c5e0eb60920e27fe99",
        "warmup_time": -1
    },
    "inmemoryarraydataset.TimeInMemoryArrayDataset.time_setattr": {
        "code": "class TimeInMemoryArrayDataset:\n    def time_setattr(self):\n        with h5py.File(\"bench.hdf5\", \"w\") as f:\n            versioned_file = VersionedHDF5File(f)\n            with versioned_file.stage_version(\"version1\") as g:\n                dataset = g.create_dataset(\n                    \"data\",\n                    data=np.arange(10000).reshape((100, 10, 10)),\n                    chunks=(3, 3, 3),\n                )\n                assert isinstance(dataset.dataset, InMemoryArrayDataset)\n                dataset[:, 0, 0:6] = -1",
        "min_run_count": 2,
        "name": "inmemoryarraydataset.TimeInMemoryArrayDataset.time_setattr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "49ee2719f4ab9daa522500a6e4eaa5055976663bfae7e811f8efd66b421a96f7",
        "warmup_time": -1
    },
    "inmemorydataset.TimeInMemoryDataset.time_getitem": {
        "code": "class TimeInMemoryDataset:\n    def time_getitem(self):\n        dataset = self.versioned_file[\"version1\"][\"data\"]\n        assert isinstance(dataset.dataset, InMemoryDataset)\n        dataset[:, 0, 0:6]\n\n    def setup(self):\n        if hasattr(self, \"file\"):\n            self.file.close()\n        if os.path.exists(\"bench.hdf5\"):\n            os.remove(\"bench.hdf5\")\n    \n        with h5py.File(\"bench.hdf5\", \"w\") as f:\n            versioned_file = VersionedHDF5File(f)\n    \n            with versioned_file.stage_version(\"version1\") as g:\n                g.create_dataset(\n                    \"data\",\n                    data=np.arange(10000).reshape((100, 10, 10)),\n                    chunks=(3, 3, 3),\n                )\n    \n        self.file = h5py.File(\"bench.hdf5\", \"a\")\n        self.versioned_file = VersionedHDF5File(self.file)",
        "min_run_count": 2,
        "name": "inmemorydataset.TimeInMemoryDataset.time_getitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "1b34b3c4cd5858eb3ccaa0e195d38f954e02a1969682957872bb62e433009eff",
        "warmup_time": -1
    },
    "inmemorydataset.TimeInMemoryDataset.time_resize_bigger": {
        "code": "class TimeInMemoryDataset:\n    def time_resize_bigger(self):\n        # https://github.com/airspeed-velocity/asv/issues/966\n        self.setup()\n        with self.versioned_file.stage_version(\"version2\") as g:\n            dataset = g[\"data\"]\n            assert isinstance(dataset.dataset, InMemoryDataset)\n            dataset.resize((100, 100, 100))\n\n    def setup(self):\n        if hasattr(self, \"file\"):\n            self.file.close()\n        if os.path.exists(\"bench.hdf5\"):\n            os.remove(\"bench.hdf5\")\n    \n        with h5py.File(\"bench.hdf5\", \"w\") as f:\n            versioned_file = VersionedHDF5File(f)\n    \n            with versioned_file.stage_version(\"version1\") as g:\n                g.create_dataset(\n                    \"data\",\n                    data=np.arange(10000).reshape((100, 10, 10)),\n                    chunks=(3, 3, 3),\n                )\n    \n        self.file = h5py.File(\"bench.hdf5\", \"a\")\n        self.versioned_file = VersionedHDF5File(self.file)",
        "min_run_count": 2,
        "name": "inmemorydataset.TimeInMemoryDataset.time_resize_bigger",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "ab24f40567b4d16506830b2a496032b9c48e6f8905f0eb64e1cd84cd6bb04bb5",
        "warmup_time": -1
    },
    "inmemorydataset.TimeInMemoryDataset.time_resize_smaller": {
        "code": "class TimeInMemoryDataset:\n    def time_resize_smaller(self):\n        # https://github.com/airspeed-velocity/asv/issues/966\n        self.setup()\n        with self.versioned_file.stage_version(\"version2\") as g:\n            dataset = g[\"data\"]\n            assert isinstance(dataset.dataset, InMemoryDataset)\n            dataset.resize((10, 10, 10))\n\n    def setup(self):\n        if hasattr(self, \"file\"):\n            self.file.close()\n        if os.path.exists(\"bench.hdf5\"):\n            os.remove(\"bench.hdf5\")\n    \n        with h5py.File(\"bench.hdf5\", \"w\") as f:\n            versioned_file = VersionedHDF5File(f)\n    \n            with versioned_file.stage_version(\"version1\") as g:\n                g.create_dataset(\n                    \"data\",\n                    data=np.arange(10000).reshape((100, 10, 10)),\n                    chunks=(3, 3, 3),\n                )\n    \n        self.file = h5py.File(\"bench.hdf5\", \"a\")\n        self.versioned_file = VersionedHDF5File(self.file)",
        "min_run_count": 2,
        "name": "inmemorydataset.TimeInMemoryDataset.time_resize_smaller",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "a7f979e3a6b2b06896c3f68c2fb8bba34daf5202617fb92e5fc654bbf4170156",
        "warmup_time": -1
    },
    "inmemorydataset.TimeInMemoryDataset.time_setitem": {
        "code": "class TimeInMemoryDataset:\n    def time_setitem(self):\n        # https://github.com/airspeed-velocity/asv/issues/966\n        self.setup()\n        with self.versioned_file.stage_version(\"version2\") as g:\n            dataset = g[\"data\"]\n            assert isinstance(dataset.dataset, InMemoryDataset)\n            dataset[:, 0, 0:6] = -1\n\n    def setup(self):\n        if hasattr(self, \"file\"):\n            self.file.close()\n        if os.path.exists(\"bench.hdf5\"):\n            os.remove(\"bench.hdf5\")\n    \n        with h5py.File(\"bench.hdf5\", \"w\") as f:\n            versioned_file = VersionedHDF5File(f)\n    \n            with versioned_file.stage_version(\"version1\") as g:\n                g.create_dataset(\n                    \"data\",\n                    data=np.arange(10000).reshape((100, 10, 10)),\n                    chunks=(3, 3, 3),\n                )\n    \n        self.file = h5py.File(\"bench.hdf5\", \"a\")\n        self.versioned_file = VersionedHDF5File(self.file)",
        "min_run_count": 2,
        "name": "inmemorydataset.TimeInMemoryDataset.time_setitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1000,
        "type": "time",
        "unit": "seconds",
        "version": "47d01179da6be445e7208065e357d1608eaf0f93de030071768060d074f6258e",
        "warmup_time": -1
    },
    "many_chunks.time_many_chunks": {
        "code": "def time_many_chunks():\n    d0 = 2\n    d1 = 15220\n    d2 = 2\n    shape = (d0, d1, d2)\n    chunks = (600, 2, 4)\n    with h5py.File(\"foo.h5\", \"w\") as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(\"0\") as sv:\n            sv.create_dataset(\n                \"bar\",\n                shape=shape,\n                maxshape=(None, None, None),\n                chunks=chunks,\n                dtype=dt,\n                data=np.full(shape, 0, dtype=dt),\n            )\n\n    i = 1\n    with h5py.File(\"foo.h5\", \"r+\") as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(str(i)) as sv:\n            sv[\"bar\"][:] = np.full(shape, i, dtype=dt)",
        "min_run_count": 2,
        "name": "many_chunks.time_many_chunks",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5128254c4c763f247bf023eacc81fe24ae2a5987ce075b73f68bf8d85b0365a9",
        "warmup_time": -1
    },
    "many_chunks.time_many_chunks_arange": {
        "code": "def time_many_chunks_arange():\n    d0 = 2\n    d1 = 15220\n    d2 = 2\n    shape = (d0, d1, d2)\n    chunks = (600, 2, 4)\n    with h5py.File(\"foo.h5\", \"w\") as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(\"0\") as sv:\n            sv.create_dataset(\n                \"bar\",\n                shape=shape,\n                maxshape=(None, None, None),\n                chunks=chunks,\n                dtype=dt,\n                data=np.arange(np.prod(shape), dtype=dt).reshape(shape),\n            )",
        "min_run_count": 2,
        "name": "many_chunks.time_many_chunks_arange",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "39b9d2291060612641481b410605f0c754b8b6bbf277faa82b2ead28f1a96175",
        "warmup_time": -1
    },
    "many_chunks.time_many_chunks_integer_index": {
        "code": "def time_many_chunks_integer_index():\n    d0 = 2\n    d1 = 15220\n    d2 = 2\n    shape = (d0, d1, d2)\n    chunks = (600, 2, 4)\n    with h5py.File(\"foo.h5\", \"w\") as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(\"0\") as sv:\n            sv.create_dataset(\n                \"bar\",\n                shape=shape,\n                maxshape=(None, None, None),\n                chunks=chunks,\n                dtype=dt,\n                data=np.full(shape, 0, dtype=dt),\n            )\n\n    i = 1\n    with h5py.File(\"foo.h5\", \"r+\") as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(str(i)) as sv:\n            i2 = np.random.choice(d1, 30, replace=False)\n            i2 = np.sort(i2)\n            sv[\"bar\"][:, i2, :] = np.full((d0, len(i2), d2), i, dtype=dt)",
        "min_run_count": 2,
        "name": "many_chunks.time_many_chunks_integer_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5c0ff9da0533ce949370d90c05e005bf03a593a30f6ecb462239776870baf06f",
        "warmup_time": -1
    },
    "resize.time_resize": {
        "code": "def time_resize():\n    with h5py.File(\"foo.h5\", \"w\") as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(\"0\") as sv:\n            sv.create_dataset(\n                \"bar\",\n                (2, 15220, 2),\n                chunks=(300, 100, 2),\n                dtype=dt,\n                data=np.full((2, 15220, 2), 0, dtype=dt),\n            )\n\n    with h5py.File(\"foo.h5\", \"r+\") as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(\"1\") as sv:\n            bar = sv[\"bar\"]\n            bar.resize((3, 15222, 2))",
        "min_run_count": 2,
        "name": "resize.time_resize",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "3b435f8557fbd56aa9a9222501394996504b4851a199dc98e054017f1a7e0a29",
        "warmup_time": -1
    },
    "resize.time_resize_and_write": {
        "code": "def time_resize_and_write():\n    with h5py.File(\"foo.h5\", \"w\") as f:\n        vf = VersionedHDF5File(f)\n        with vf.stage_version(\"0\") as sv:\n            sv.create_dataset(\n                \"bar\",\n                (1, 10, 2),\n                chunks=(600, 2, 4),\n                dtype=dt,\n                data=np.full((1, 10, 2), 0, dtype=dt),\n            )\n\n    for i in range(1, 100):\n        with h5py.File(\"foo.h5\", \"r+\") as f:\n            vf = VersionedHDF5File(f)\n            with vf.stage_version(str(i)) as sv:\n                bar = sv[\"bar\"]\n                bar.resize((1, (i + 1) * 10, 2))\n                bar[:, -10:, :] = np.full((1, 10, 2), i, dtype=dt)",
        "min_run_count": 2,
        "name": "resize.time_resize_and_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "619858ee9c90cded4ef70b7a33ccab53413c781f05be4a1bcf0abe76848a71bd",
        "warmup_time": -1
    },
    "resize.time_resize_and_write_hdf5": {
        "code": "def time_resize_and_write_hdf5():\n    with h5py.File(\"foo.h5\", \"w\") as f:\n        f.create_dataset(\n            \"bar0\",\n            (1, 10, 2),\n            chunks=(600, 2, 4),\n            dtype=dt,\n            data=np.full((1, 10, 2), 0, dtype=dt),\n            maxshape=(None, None, None),\n        )\n\n    for i in range(1, 100):\n        with h5py.File(\"foo.h5\", \"r+\") as f:\n            bar = f.create_dataset(\n                \"bar%d\" % i,\n                chunks=(600, 2, 4),\n                dtype=dt,\n                data=f[\"bar%d\" % (i - 1)],\n                maxshape=(None, None, None),\n            )\n            bar.resize((1, (i + 1) * 10, 2))\n            bar[:, -10:, :] = np.full((1, 10, 2), i, dtype=dt)",
        "min_run_count": 2,
        "name": "resize.time_resize_and_write_hdf5",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "923f46a6c04c45a4e35593462d3bbe8579720b3e5344d64494bd0386e184a240",
        "warmup_time": -1
    },
    "resize.time_resize_and_write_hdf5_no_copy": {
        "code": "def time_resize_and_write_hdf5_no_copy():\n    with h5py.File(\"foo.h5\", \"w\") as f:\n        f.create_dataset(\n            \"bar\",\n            (1, 10, 2),\n            chunks=(600, 2, 4),\n            dtype=dt,\n            data=np.full((1, 10, 2), 0, dtype=dt),\n            maxshape=(None, None, None),\n        )\n\n    for i in range(1, 100):\n        with h5py.File(\"foo.h5\", \"r+\") as f:\n            bar = f[\"bar\"]\n            bar.resize((1, (i + 1) * 10, 2))\n            bar[:, -10:, :] = np.full((1, 10, 2), i, dtype=dt)",
        "min_run_count": 2,
        "name": "resize.time_resize_and_write_hdf5_no_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5c5cc69ef81f8cc294ce95836273bf6b764edd4b8a172ffbe5782f9c8f60dfd0",
        "warmup_time": -1
    },
    "resize.time_resize_hdf5": {
        "code": "def time_resize_hdf5():\n    with h5py.File(\"foo.h5\", \"w\") as f:\n        f.create_dataset(\n            \"bar\",\n            (2, 15220, 2),\n            chunks=(300, 100, 2),\n            dtype=dt,\n            data=np.full((2, 15220, 2), 0, dtype=dt),\n            maxshape=(None, None, None),\n        )\n\n    with h5py.File(\"foo.h5\", \"r+\") as f:\n        bar = f[\"bar\"]\n        bar.resize((3, 15222, 2))",
        "min_run_count": 2,
        "name": "resize.time_resize_hdf5",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "9b7499318eac109686c8f659e6db39376fdef6c9536eb610893ccbe0450d92b8",
        "warmup_time": -1
    },
    "version": 2,
    "versionedhdf5file.TimeDatetimeAccess.time_version_by_datetime": {
        "code": "class TimeDatetimeAccess:\n    def time_version_by_datetime(self):\n        # Based on https://github.com/deshaw/versioned-hdf5/issues/170\n        with h5py.File(\"foo.h5\", \"r\") as f:\n            vf = VersionedHDF5File(f)\n            for _ in range(100):\n                _ = vf[self.dt][\"bar\"][:]\n\n    def setup(self):\n        with h5py.File(\"foo.h5\", \"w\") as f:\n            vf = VersionedHDF5File(f)\n            with vf.stage_version(\"0\") as sv:\n                sv.create_dataset(\"bar\", data=np.random.rand(10))\n    \n            for i in range(1, 100):\n                with vf.stage_version(str(i)) as sv:\n                    sv[\"bar\"][:] = np.random.rand(10)\n            self.dt = np.datetime64(vf[str(50)].attrs[\"timestamp\"])",
        "min_run_count": 2,
        "name": "versionedhdf5file.TimeDatetimeAccess.time_version_by_datetime",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "88d19929641c170823707cd13e6f74fd276752973123b962f84dfb4e496757ac",
        "warmup_time": -1
    }
}